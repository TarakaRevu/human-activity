{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PranayLendave/video_classification/blob/main/trained_movinets_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xXTGfjZeCkO"
   },
   "source": [
    "## Video Classification\n",
    "\n",
    "This notebook provides basic example code to build, run, and fine-tune [MoViNets (Mobile Video Networks)](https://arxiv.org/pdf/2103.11511.pdf).\n",
    "\n",
    "Pretrained models are provided by [TensorFlow Hub](https://tfhub.dev/google/collections/movinet/) and the [TensorFlow Model Garden](https://github.com/tensorflow/models/tree/master/official/projects/movinet), trained on [UCF101](https://www.crcv.ucf.edu/data/UCF101.php) for video action classification. All Models use TensorFlow 2 with Keras for inference and training.\n",
    "\n",
    "The following steps will be performed:\n",
    "\n",
    "1. [Installation](#scrollTo=dPx7Pp7fbgLY&uniqifier=1)\n",
    "2. [Download a subset of the UCF101 dataset](#scrollTo=KbhwWLLM7FXo&uniqifier=1)\n",
    "3. [Download a pre-trained MoViNet model](#scrollTo=aYYShfhMx9DW&uniqifier=1)\n",
    "4. [Save and load model](#scrollTo=YDk6LAciJfnA&uniqifier=1)\n",
    "5. [Evaluate the model](#scrollTo=KkLl2zF8G9W0&uniqifier=1)\n",
    "6. [Inferencing using the trained model on GIF](#scrollTo=6s9Q_JBcVmN1&uniqifier=1)\n",
    "\n",
    "**Note: Enabling GPU Acceleration**\n",
    "\n",
    "To utilize GPU acceleration in Colab, follow these steps:\n",
    "\n",
    "1. Click on the \"Runtime\" menu at the top.\n",
    "2. Select \"Change runtime type\" from the dropdown menu.\n",
    "3. In the dialog box, choose \"GPU\" as the hardware accelerator.\n",
    "4. Click on the \"Save\" button.\n",
    "\n",
    "Enabling GPU will allow you to take advantage of faster computation for deep learning tasks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPx7Pp7fbgLY"
   },
   "source": [
    "## Installation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ssfc-BPfBI1",
    "outputId": "0addd703-deea-41ae-cf7d-a749fcdd5a92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: '/content/'\n",
      "C:\\Users\\revut\\Downloads\\video_classification-main\\video_classification-main\n"
     ]
    }
   ],
   "source": [
    "%cd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XloHnNOTiJjt",
    "outputId": "dc626027-0b04-4e11-fea5-7f46d2648c8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revut\\Downloads\\video_classification-main\\video_classification-main\\video_classification\n"
     ]
    }
   ],
   "source": [
    "!mkdir video_classification\n",
    "%cd video_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UusG__Cfdn77"
   },
   "source": [
    "Install Dependencies: Run the following code block to install the necessary dependencies, including remotezip, tqdm, opencv-python, tf-models-official, and other required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OreRoZQc148d"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install remotezip tqdm opencv-python==4.5.2.52 opencv-python-headless==4.5.2.52 tf-models-official\n",
    "!pip install remotezip\n",
    "!pip install tf-models-official\n",
    "!pip install -q mediapy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IxptbOXI932"
   },
   "source": [
    "Import Libraries: Make sure to import the essential libraries for video processing, data manipulation, visualization, and deep learning operations. Include the following modules in your code:\n",
    "\n",
    "**NOTE!!**: Below code might give you an error but running it again would solve the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QImPsudoK9JI"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mremotezip\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrz\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import random\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import remotezip as rz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# Import the MoViNet model from TensorFlow Models (tf-models-official) for the MoViNet model\n",
    "from official.projects.movinet.modeling import movinet\n",
    "from official.projects.movinet.modeling import movinet_model\n",
    "\n",
    "import mediapy as media\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6OlKeK8ew4A"
   },
   "source": [
    "With these installation and import steps completed, you are now ready to leverage the power of MoViNet for accurate video classification.\n",
    "\n",
    "Feel free to customize the installation and import instructions based on your specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbhwWLLM7FXo"
   },
   "source": [
    "## Download a subset of the UCF101 dataset\n",
    "\n",
    "The [UCF101 dataset](https://www.tensorflow.org/datasets/catalog/ucf101) contains 101 categories of different actions in video, primarily used in action recognition. You will use a subset of these categories in this demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GM4gvQopfQ6a"
   },
   "source": [
    "These helper functions collectively assist in various stages of video processing, model loading, classification, and result visualization. They enhance the functionality and usability of the code by encapsulating specific tasks and making the code more modular and organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PASTmmsObpf4"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "\n",
    "def get_class(fname):\n",
    "  \"\"\" Retrieve the name of the class given a filename.\n",
    "\n",
    "    Args:\n",
    "      fname: Name of the file in the UCF101 dataset.\n",
    "\n",
    "    Returns:\n",
    "      Class that the file belongs to.\n",
    "  \"\"\"\n",
    "  return fname.split('_')[-3]\n",
    "\n",
    "\n",
    "def list_files_per_class(zip_url):\n",
    "  \"\"\"\n",
    "    List the files in each class of the dataset given the zip URL.\n",
    "\n",
    "    Args:\n",
    "      zip_url: URL from which the files can be unzipped.\n",
    "\n",
    "    Return:\n",
    "      files: List of files in each of the classes.\n",
    "  \"\"\"\n",
    "  files = []\n",
    "  with rz.RemoteZip(URL) as zip:\n",
    "    for zip_info in zip.infolist():\n",
    "      files.append(zip_info.filename)\n",
    "  return files\n",
    "\n",
    "def get_class(fname):\n",
    "  \"\"\"\n",
    "    Retrieve the name of the class given a filename.\n",
    "\n",
    "    Args:\n",
    "      fname: Name of the file in the UCF101 dataset.\n",
    "\n",
    "    Return:\n",
    "      Class that the file belongs to.\n",
    "  \"\"\"\n",
    "  return fname.split('_')[-3]\n",
    "\n",
    "def get_files_per_class(files):\n",
    "  \"\"\"\n",
    "    Retrieve the files that belong to each class.\n",
    "\n",
    "    Args:\n",
    "      files: List of files in the dataset.\n",
    "\n",
    "    Return:\n",
    "      Dictionary of class names (key) and files (values).\n",
    "  \"\"\"\n",
    "  files_for_class = collections.defaultdict(list)\n",
    "  for fname in files:\n",
    "    class_name = get_class(fname)\n",
    "    files_for_class[class_name].append(fname)\n",
    "  return files_for_class\n",
    "\n",
    "def select_subset_of_classes(files_for_class, classes, files_per_class):\n",
    "  \"\"\" Create a dictionary with the class name and a subset of the files in that class.\n",
    "\n",
    "    Args:\n",
    "      files_for_class: Dictionary of class names (key) and files (values).\n",
    "      classes: List of classes.\n",
    "      files_per_class: Number of files per class of interest.\n",
    "\n",
    "    Returns:\n",
    "      Dictionary with class as key and list of specified number of video files in that class.\n",
    "  \"\"\"\n",
    "  files_subset = dict()\n",
    "\n",
    "  for class_name in classes:\n",
    "    class_files = files_for_class[class_name]\n",
    "    files_subset[class_name] = class_files[:files_per_class]\n",
    "\n",
    "  return files_subset\n",
    "\n",
    "def download_from_zip(zip_url, to_dir, file_names):\n",
    "  \"\"\" Download the contents of the zip file from the zip URL.\n",
    "\n",
    "    Args:\n",
    "      zip_url: A URL with a zip file containing data.\n",
    "      to_dir: A directory to download data to.\n",
    "      file_names: Names of files to download.\n",
    "  \"\"\"\n",
    "  with rz.RemoteZip(zip_url) as zip:\n",
    "    for fn in tqdm.tqdm(file_names):\n",
    "      class_name = get_class(fn)\n",
    "      zip.extract(fn, str(to_dir / class_name))\n",
    "      unzipped_file = to_dir / class_name / fn\n",
    "\n",
    "      fn = pathlib.Path(fn).parts[-1]\n",
    "      output_file = to_dir / class_name / fn\n",
    "      unzipped_file.rename(output_file)\n",
    "\n",
    "def split_class_lists(files_for_class, count):\n",
    "  \"\"\"\n",
    "    Returns the list of files belonging to a subset of data as well as the remainder of\n",
    "    files that need to be downloaded.\n",
    "\n",
    "    Args:\n",
    "      files_for_class: Files belonging to a particular class of data.\n",
    "      count: Number of files to download.\n",
    "\n",
    "    Return:\n",
    "      split_files: Files belonging to the subset of data.\n",
    "      remainder: Dictionary of the remainder of files that need to be downloaded.\n",
    "  \"\"\"\n",
    "  split_files = []\n",
    "  remainder = {}\n",
    "  for cls in files_for_class:\n",
    "    split_files.extend(files_for_class[cls][:count])\n",
    "    remainder[cls] = files_for_class[cls][count:]\n",
    "  return split_files, remainder\n",
    "\n",
    "def download_ucf_101_subset(zip_url, num_classes, splits, download_dir,classes_1):\n",
    "  \"\"\" Download a subset of the UCF101 dataset and split them into various parts, such as\n",
    "    training, validation, and test.\n",
    "\n",
    "    Args:\n",
    "      zip_url: A URL with a ZIP file with the data.\n",
    "      num_classes: Number of labels.\n",
    "      splits: Dictionary specifying the training, validation, test, etc. (key) division of data\n",
    "              (value is number of files per split).\n",
    "      download_dir: Directory to download data to.\n",
    "\n",
    "    Return:\n",
    "      Mapping of the directories containing the subsections of data.\n",
    "  \"\"\"\n",
    "  files = list_files_from_zip_url(zip_url)\n",
    "  for f in files:\n",
    "    path = os.path.normpath(f)\n",
    "    tokens = path.split(os.sep)\n",
    "    if len(tokens) <= 2:\n",
    "      files.remove(f) # Remove that item from the list if it does not have a filename\n",
    "\n",
    "  files_for_class = get_files_per_class(files)\n",
    "\n",
    "  # classes = list(files_for_class.keys())[:num_classes]\n",
    "  classes = classes_1\n",
    "\n",
    "  for cls in classes:\n",
    "    random.shuffle(files_for_class[cls])\n",
    "\n",
    "  # Only use the number of classes you want in the dictionary\n",
    "  files_for_class = {x: files_for_class[x] for x in classes}\n",
    "\n",
    "  dirs = {}\n",
    "  for split_name, split_count in splits.items():\n",
    "    print(split_name, \":\")\n",
    "    split_dir = download_dir / split_name\n",
    "    split_files, files_for_class = split_class_lists(files_for_class, split_count)\n",
    "    download_from_zip(zip_url, split_dir, split_files)\n",
    "    dirs[split_name] = split_dir\n",
    "\n",
    "  return dirs\n",
    "\n",
    "def format_frames(frame, output_size):\n",
    "  \"\"\"\n",
    "    Pad and resize an image from a video.\n",
    "\n",
    "    Args:\n",
    "      frame: Image that needs to resized and padded.\n",
    "      output_size: Pixel size of the output frame image.\n",
    "\n",
    "    Return:\n",
    "      Formatted frame with padding of specified output size.\n",
    "  \"\"\"\n",
    "  frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "  frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "  return frame\n",
    "\n",
    "def frames_from_video_file(video_path, n_frames, output_size = (224,224), frame_step = 15):\n",
    "  \"\"\"\n",
    "    Creates frames from each video file present for each category.\n",
    "\n",
    "    Args:\n",
    "      video_path: File path to the video.\n",
    "      n_frames: Number of frames to be created per video file.\n",
    "      output_size: Pixel size of the output frame image.\n",
    "\n",
    "    Return:\n",
    "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
    "  \"\"\"\n",
    "  # Read each video frame by frame\n",
    "  result = []\n",
    "  src = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "  need_length = 1 + (n_frames - 1) * frame_step\n",
    "\n",
    "  if need_length > video_length:\n",
    "    start = 0\n",
    "  else:\n",
    "    max_start = video_length - need_length\n",
    "    start = random.randint(0, max_start + 1)\n",
    "\n",
    "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "  # ret is a boolean indicating whether read was successful, frame is the image itself\n",
    "  ret, frame = src.read()\n",
    "  result.append(format_frames(frame, output_size))\n",
    "\n",
    "  for _ in range(n_frames - 1):\n",
    "    for _ in range(frame_step):\n",
    "      ret, frame = src.read()\n",
    "    if ret:\n",
    "      frame = format_frames(frame, output_size)\n",
    "      result.append(frame)\n",
    "    else:\n",
    "      result.append(np.zeros_like(result[0]))\n",
    "  src.release()\n",
    "  result = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "  return result\n",
    "\n",
    "def list_files_from_zip_url(zip_url):\n",
    "  \"\"\" List the files in each class of the dataset given a URL with the zip file.\n",
    "\n",
    "    Args:\n",
    "      zip_url: A URL from which the files can be extracted from.\n",
    "\n",
    "    Returns:\n",
    "      List of files in each of the classes.\n",
    "  \"\"\"\n",
    "  files = []\n",
    "  with rz.RemoteZip(zip_url) as zip:\n",
    "    for zip_info in zip.infolist():\n",
    "      files.append(zip_info.filename)\n",
    "  return files\n",
    "\n",
    "class FrameGenerator:\n",
    "  def __init__(self, path, n_frames, training = False):\n",
    "    \"\"\" Returns a set of frames with their associated label.\n",
    "\n",
    "      Args:\n",
    "        path: Video file paths.\n",
    "        n_frames: Number of frames.\n",
    "        training: Boolean to determine if training dataset is being created.\n",
    "    \"\"\"\n",
    "    self.path = path\n",
    "    self.n_frames = n_frames\n",
    "    self.training = training\n",
    "    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
    "    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
    "\n",
    "  def get_files_and_class_names(self):\n",
    "    video_paths = list(self.path.glob('*/*.avi'))\n",
    "    classes = [p.parent.name for p in video_paths]\n",
    "    return video_paths, classes\n",
    "\n",
    "  def __call__(self):\n",
    "    video_paths, classes = self.get_files_and_class_names()\n",
    "\n",
    "    pairs = list(zip(video_paths, classes))\n",
    "\n",
    "    if self.training:\n",
    "      random.shuffle(pairs)\n",
    "\n",
    "    for path, name in pairs:\n",
    "      video_frames = frames_from_video_file(path, self.n_frames)\n",
    "      label = self.class_ids_for_name[name] # Encode labels\n",
    "      yield video_frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lY-x7TaZlK6O"
   },
   "outputs": [],
   "source": [
    "def list_files_from_zip_url(zip_url):\n",
    "  \"\"\" List the files in each class of the dataset given a URL with the zip file.\n",
    "\n",
    "    Args:\n",
    "      zip_url: A URL from which the files can be extracted from.\n",
    "\n",
    "    Returns:\n",
    "      List of files in each of the classes.\n",
    "  \"\"\"\n",
    "  files = []\n",
    "  with rz.RemoteZip(zip_url) as zip:\n",
    "    for zip_info in zip.infolist():\n",
    "      files.append(zip_info.filename)\n",
    "  return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYErXAdUr-rk",
    "outputId": "0967db30-58e4-4d4f-8181-3c7845ecac13"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'URL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m files \u001b[38;5;241m=\u001b[39m list_files_from_zip_url(URL)\n\u001b[0;32m      2\u001b[0m files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.avi\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      3\u001b[0m files[:\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'URL' is not defined"
     ]
    }
   ],
   "source": [
    "files = list_files_from_zip_url(URL)\n",
    "files = [f for f in files if f.endswith('.avi')]\n",
    "files[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQ4l8D9dFPS7"
   },
   "source": [
    "Begin with a few videos and a limited number of classes for training. After running the above code block, notice that the class name is included in the filename of each video.\n",
    "\n",
    "Define the `get_class` function that retrieves the class name from a filename. Then, create a function called `get_files_per_class` which converts the list of all files (`files` above) into a dictionary listing the files for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yyyivOX0sO19"
   },
   "outputs": [],
   "source": [
    "def get_class(fname):\n",
    "  \"\"\" Retrieve the name of the class given a filename.\n",
    "\n",
    "    Args:\n",
    "      fname: Name of the file in the UCF101 dataset.\n",
    "\n",
    "    Returns:\n",
    "      Class that the file belongs to.\n",
    "  \"\"\"\n",
    "  return fname.split('_')[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qnH0xKzlyw_"
   },
   "outputs": [],
   "source": [
    "def get_files_per_class(files):\n",
    "  \"\"\" Retrieve the files that belong to each class.\n",
    "\n",
    "    Args:\n",
    "      files: List of files in the dataset.\n",
    "\n",
    "    Returns:\n",
    "      Dictionary of class names (key) and files (values).\n",
    "  \"\"\"\n",
    "  files_for_class = collections.defaultdict(list)\n",
    "  for fname in files:\n",
    "    class_name = get_class(fname)\n",
    "    files_for_class[class_name].append(fname)\n",
    "  return files_for_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxSt5YgSGrWn"
   },
   "source": [
    "Once you have the list of files per class, you can choose how many classes you would like to use and how many videos you would like per class in order to create your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPdURg74uUTk"
   },
   "outputs": [],
   "source": [
    "FILES_PER_CLASS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUs0xtXsr9i3"
   },
   "outputs": [],
   "source": [
    "files_for_class = get_files_per_class(files)\n",
    "classes = list(files_for_class.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N62fE2aPcm2_"
   },
   "source": [
    "All the classes of UCF101 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2z2vc8iMNYL",
    "outputId": "98315fdf-d556-4c46-d6ee-385e66e90e3c"
   },
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0R1rnWuJcsBn"
   },
   "source": [
    "These are the selected classes from the above classes list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBvC66zrMfq1"
   },
   "outputs": [],
   "source": [
    "classes_1 = ['Archery',\n",
    " 'BabyCrawling',\n",
    " 'BoxingPunchingBag',\n",
    " 'BoxingSpeedBag',\n",
    " 'CliffDiving',\n",
    " 'CuttingInKitchen',\n",
    " 'Diving',\n",
    " 'Fencing',\n",
    " 'Hammering',\n",
    " 'HammerThrow',\n",
    " 'HighJump',\n",
    " 'HulaHoop',\n",
    " 'IceDancing',\n",
    " 'JavelinThrow',\n",
    " 'LongJump',\n",
    " 'Mixing',\n",
    " 'MoppingFloor',\n",
    " 'PoleVault',\n",
    " 'Punch',\n",
    " 'SalsaSpin',\n",
    " 'Shotput',\n",
    " 'SumoWrestling',\n",
    " 'TaiChi',\n",
    " 'ThrowDiscus',\n",
    " 'TrampolineJumping']\n",
    "\n",
    "NUM_CLASSES = len(classes_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YqFARvqwon9",
    "outputId": "48326dfc-9bc1-442a-a57a-06c05789f693"
   },
   "outputs": [],
   "source": [
    "print('Num classes:', len(classes))\n",
    "print('Num videos for class[0]:', len(files_for_class[classes[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFAFqKqE92bQ"
   },
   "source": [
    "Create a new function called `select_subset_of_classes` that selects a subset of the classes present within the dataset and a particular number of files per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3jek4QimIj-"
   },
   "outputs": [],
   "source": [
    "def select_subset_of_classes(files_for_class, classes, files_per_class):\n",
    "  \"\"\" Create a dictionary with the class name and a subset of the files in that class.\n",
    "\n",
    "    Args:\n",
    "      files_for_class: Dictionary of class names (key) and files (values).\n",
    "      classes: List of classes.\n",
    "      files_per_class: Number of files per class of interest.\n",
    "\n",
    "    Returns:\n",
    "      Dictionary with class as key and list of specified number of video files in that class.\n",
    "  \"\"\"\n",
    "  files_subset = dict()\n",
    "\n",
    "  for class_name in classes:\n",
    "    class_files = files_for_class[class_name]\n",
    "    files_subset[class_name] = class_files[:files_per_class]\n",
    "\n",
    "  return files_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cjcz6Gpcb-W",
    "outputId": "63527e56-cc4e-4cf8-c3d2-a8f10a648f08"
   },
   "outputs": [],
   "source": [
    "files_subset = select_subset_of_classes(files_for_class, classes_1, FILES_PER_CLASS)\n",
    "list(files_subset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALrlDS1lZx3E"
   },
   "source": [
    "Define helper functions that split the videos into training, validation, and test sets. The videos are downloaded from a URL with the zip file, and placed into their respective subdirectiories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AH9sWS_6nRz3"
   },
   "outputs": [],
   "source": [
    "def download_from_zip(zip_url, to_dir, file_names):\n",
    "  \"\"\" Download the contents of the zip file from the zip URL.\n",
    "\n",
    "    Args:\n",
    "      zip_url: A URL with a zip file containing data.\n",
    "      to_dir: A directory to download data to.\n",
    "      file_names: Names of files to download.\n",
    "  \"\"\"\n",
    "  with rz.RemoteZip(zip_url) as zip:\n",
    "    for fn in tqdm.tqdm(file_names):\n",
    "      class_name = get_class(fn)\n",
    "      zip.extract(fn, str(to_dir / class_name))\n",
    "      unzipped_file = to_dir / class_name / fn\n",
    "\n",
    "      fn = pathlib.Path(fn).parts[-1]\n",
    "      output_file = to_dir / class_name / fn\n",
    "      unzipped_file.rename(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pejRTChA6mrp"
   },
   "source": [
    "The following function returns the remaining data that hasn't already been placed into a subset of data. It allows you to place that remaining data in the next specified subset of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ARYc-WLqqNF"
   },
   "outputs": [],
   "source": [
    "def split_class_lists(files_for_class, count):\n",
    "  \"\"\" Returns the list of files belonging to a subset of data as well as the remainder of\n",
    "    files that need to be downloaded.\n",
    "\n",
    "    Args:\n",
    "      files_for_class: Files belonging to a particular class of data.\n",
    "      count: Number of files to download.\n",
    "\n",
    "    Returns:\n",
    "      Files belonging to the subset of data and dictionary of the remainder of files that need to be downloaded.\n",
    "  \"\"\"\n",
    "  split_files = []\n",
    "  remainder = {}\n",
    "  for cls in files_for_class:\n",
    "    split_files.extend(files_for_class[cls][:count])\n",
    "    remainder[cls] = files_for_class[cls][count:]\n",
    "  return split_files, remainder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlEQ_I0TLd1X"
   },
   "source": [
    "The following `download_ucf_101_subset` function allows you to download a subset of the UCF101 dataset and split it into the training, validation, and test sets. You can specify the number of classes that you would like to use. The `splits` argument allows you to pass in a dictionary in which the key values are the name of subset (example: \"train\") and the number of videos you would like to have per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHH2Y1M06xoz"
   },
   "outputs": [],
   "source": [
    "def download_ucf_101_subset(zip_url, num_classes, splits, download_dir,classes_1):\n",
    "  \"\"\" Download a subset of the UCF101 dataset and split them into various parts, such as\n",
    "    training, validation, and test.\n",
    "\n",
    "    Args:\n",
    "      zip_url: A URL with a ZIP file with the data.\n",
    "      num_classes: Number of labels.\n",
    "      splits: Dictionary specifying the training, validation, test, etc. (key) division of data\n",
    "              (value is number of files per split).\n",
    "      download_dir: Directory to download data to.\n",
    "\n",
    "    Return:\n",
    "      Mapping of the directories containing the subsections of data.\n",
    "  \"\"\"\n",
    "  files = list_files_from_zip_url(zip_url)\n",
    "  for f in files:\n",
    "    path = os.path.normpath(f)\n",
    "    tokens = path.split(os.sep)\n",
    "    if len(tokens) <= 2:\n",
    "      files.remove(f) # Remove that item from the list if it does not have a filename\n",
    "\n",
    "  files_for_class = get_files_per_class(files)\n",
    "\n",
    "  # classes = list(files_for_class.keys())[:num_classes]\n",
    "  classes = classes_1\n",
    "\n",
    "  for cls in classes:\n",
    "    random.shuffle(files_for_class[cls])\n",
    "\n",
    "  # Only use the number of classes you want in the dictionary\n",
    "  files_for_class = {x: files_for_class[x] for x in classes}\n",
    "\n",
    "  dirs = {}\n",
    "  for split_name, split_count in splits.items():\n",
    "    print(split_name, \":\")\n",
    "    split_dir = download_dir / split_name\n",
    "    split_files, files_for_class = split_class_lists(files_for_class, split_count)\n",
    "    download_from_zip(zip_url, split_dir, split_files)\n",
    "    dirs[split_name] = split_dir\n",
    "\n",
    "  return dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpB7E8pcn4Xi"
   },
   "source": [
    "The below URL contains a zip file with the UCF 101 dataset. Create a function that uses the `remotezip` library to examine the contents of the zip file in that URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0c70mgMpgyM9"
   },
   "outputs": [],
   "source": [
    " URL = 'https://storage.googleapis.com/thumos14_files/UCF101_videos.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NuD-xU8Q66Vm",
    "outputId": "925c2882-f40d-4132-d5e7-a76a6907ec89"
   },
   "outputs": [],
   "source": [
    "download_dir = pathlib.Path('./UCF101_subset/')\n",
    "subset_paths = download_ucf_101_subset(URL,\n",
    "                                       num_classes = NUM_CLASSES,\n",
    "                                       splits = {\"train\": 30, \"val\": 10, \"test\": 10},\n",
    "                                       download_dir = download_dir,\n",
    "                                       classes_1=classes_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBMRm9Ub3Zrk"
   },
   "source": [
    "After downloading the data, you should now have a copy of a subset of the UCF101 dataset. Run the following code to print the total number of videos you have amongst all your subsets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zupvOLYP4D4q",
    "outputId": "652b95ca-357e-4d36-a23f-51916fedf5ca"
   },
   "outputs": [],
   "source": [
    "video_count_train = len(list(download_dir.glob('train/*/*.avi')))\n",
    "video_count_val = len(list(download_dir.glob('val/*/*.avi')))\n",
    "video_count_test = len(list(download_dir.glob('test/*/*.avi')))\n",
    "video_total = video_count_train + video_count_val + video_count_test\n",
    "print(f\"Total videos: {video_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYYShfhMx9DW"
   },
   "source": [
    "## Create the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-twTu3_Bx-iJ"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_frames = 8\n",
    "\n",
    "output_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
    "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['train'], num_frames, training = True),\n",
    "                                          output_signature = output_signature)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['test'], num_frames),\n",
    "                                         output_signature = output_signature)\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['val'], num_frames),\n",
    "                                          output_signature = output_signature)\n",
    "val_ds = val_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7stgmuBCGQT"
   },
   "source": [
    "The labels generated here represent the encoding of the classes. For instance, 'ApplyEyeMakeup' is mapped to the integer Take a look at the labels of the training data to ensure that the dataset has been sufficiently shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9L2-toXCOQq",
    "outputId": "f7060308-e7d0-44fe-dd97-b1a0a8ad97af"
   },
   "outputs": [],
   "source": [
    "for frames, labels in train_ds.take(NUM_CLASSES):\n",
    "  print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZ3qwZnpfy9c"
   },
   "source": [
    "Take a look at the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6MqP4m2fyQT",
    "outputId": "dd5fef74-b84b-43eb-97c0-765b430307fa"
   },
   "outputs": [],
   "source": [
    "print(f\"Shape: {frames.shape}\")\n",
    "print(f\"Label: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "A9L7BLA-s3R6",
    "outputId": "119cef37-a669-4838-f469-35d5cdb94155"
   },
   "outputs": [],
   "source": [
    "videos, labels = next(iter(train_ds))\n",
    "media.show_videos(videos.numpy(), codec='gif', fps=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UsxiPs8yA2e"
   },
   "source": [
    "## Download a pre-trained MoViNet model\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "1. We can create a MoViNet model using the open source code provided in [`official/projects/movinet`](https://github.com/tensorflow/models/tree/master/official/projects/movinet) from TensorFlow models.\n",
    "2. Load the pretrained weights.\n",
    "3. Freeze the convolutional base, or all other layers except the final classifier head, to speed up fine-tuning.\n",
    "\n",
    "To build the model, we can start with the `a0` configuration because it is the fastest to train when benchmarked against other models. Check out the [available MoViNet models on TensorFlow Model Garden](https://github.com/tensorflow/models/blob/master/official/projects/movinet/configs/movinet.py) to find what might work for our use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhSCM6cee05F",
    "outputId": "43d2546d-7200-44a9-8802-8c5ad5a53a74"
   },
   "outputs": [],
   "source": [
    "model_id = 'a0'\n",
    "resolution = 224\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "backbone = movinet.Movinet(model_id=model_id)\n",
    "backbone.trainable = False\n",
    "\n",
    "# Set num_classes=600 to load the pre-trained weights from the original model\n",
    "model = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600)\n",
    "model.build([None, None, None, None, 3])\n",
    "\n",
    "# Load pre-trained weights\n",
    "!wget https://storage.googleapis.com/tf_model_garden/vision/movinet/movinet_a0_base.tar.gz -O movinet_a0_base.tar.gz -q\n",
    "!tar -xvf movinet_a0_base.tar.gz\n",
    "\n",
    "checkpoint_dir = f'movinet_{model_id}_base'\n",
    "checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "status = checkpoint.restore(checkpoint_path)\n",
    "status.assert_existing_objects_matched()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW23HVNtCXff"
   },
   "source": [
    "To build a classifier, create a function that takes the backbone and the number of classes in a dataset. The `build_classifier` function will take the backbone and the number of classes in a dataset to build the classifier. In this case, the new classifier will take a `num_classes` outputs (10 classes for this subset of UCF101)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cfAelbU5Gi3"
   },
   "outputs": [],
   "source": [
    "def build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n",
    "  \"\"\"Builds a classifier on top of a backbone model.\"\"\"\n",
    "  model = movinet_model.MovinetClassifier(\n",
    "      backbone=backbone,\n",
    "      num_classes=num_classes)\n",
    "  model.build([batch_size, num_frames, resolution, resolution, 3])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqYZd37jo_fl",
    "outputId": "44f4b81c-9d05-4d47-eb52-377f507f622b"
   },
   "outputs": [],
   "source": [
    "batch_size, num_frames, resolution, backbone, NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HWSk-u7oPUZ"
   },
   "outputs": [],
   "source": [
    "model = build_classifier(batch_size, num_frames, resolution, backbone, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CU16MYawiWOA",
    "outputId": "c2be5184-281b-429c-d5b0-dd2c9cc24ae0"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhbX7qdTN8lc"
   },
   "source": [
    "For this tutorial, choose the `tf.keras.optimizers.Adam` optimizer and the `tf.keras.losses.SparseCategoricalCrossentropy` loss function. Use the metrics argument to the view the accuracy of the model performance at every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVqBLrn1tBsd"
   },
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "\n",
    "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "model.compile(loss=loss_obj, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VflEr_t6CuQu"
   },
   "source": [
    "Train the model. After two epochs, observe a low loss with high accuracy for both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LS4ySVP6shzs",
    "outputId": "42f57033-2f6c-48e7-b8a1-3dafb81d8e3f"
   },
   "outputs": [],
   "source": [
    "train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZeiYzI0tqQG",
    "outputId": "cb297870-8be4-4f46-9354-7bc15ee849a2"
   },
   "outputs": [],
   "source": [
    "results = model.fit(train_ds,\n",
    "                    validation_data=test_ds,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_freq=1,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDk6LAciJfnA"
   },
   "source": [
    "## Save and load model\n",
    "\n",
    "This block contains codes for saving and loading trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9cY1xYpos4i",
    "outputId": "7c8378c4-02fb-4cd7-c233-0607114cc262"
   },
   "outputs": [],
   "source": [
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHlwI3VUqinv"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the folder path to be downloaded\n",
    "folder_path = '/content/saved_model/my_model'  # Replace with the actual path to your folder\n",
    "\n",
    "# Create a zip file of the folder\n",
    "shutil.make_archive('/content/my_model', 'zip', folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srpTc6lCuJ5H"
   },
   "outputs": [],
   "source": [
    "# Download the zip file\n",
    "from google.colab import files\n",
    "\n",
    "files.download('/content/my_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQKBDQxd_sCT",
    "outputId": "e68bc64f-6a3e-4392-bfa9-f224146263f6"
   },
   "outputs": [],
   "source": [
    "!unzip /content/my_model.zip -d /content/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vUFgXorFpWUM",
    "outputId": "37ba68f0-2b3f-4e83-8d82-bcb29c6c1274"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/content/my_model')\n",
    "\n",
    "# Check its architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkLl2zF8G9W0"
   },
   "source": [
    "## Evaluate the model\n",
    "\n",
    "The model achieved high accuracy on the training dataset. Next, use Keras `Model.evaluate` to evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xt52679QdYiJ"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  \"\"\"\n",
    "    Plotting training and validation learning curves.\n",
    "\n",
    "    Args:\n",
    "      history: model history with all the metric measures\n",
    "  \"\"\"\n",
    "  fig, (ax1, ax2) = plt.subplots(2)\n",
    "\n",
    "  fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "  # Plot loss\n",
    "  ax1.set_title('Loss')\n",
    "  ax1.plot(history.history['loss'], label = 'train')\n",
    "  ax1.plot(history.history['val_loss'], label = 'test')\n",
    "  ax1.set_ylabel('Loss')\n",
    "\n",
    "  # Determine upper bound of y-axis\n",
    "  max_loss = max(history.history['loss'] + history.history['val_loss'])\n",
    "\n",
    "  ax1.set_ylim([0, np.ceil(max_loss)])\n",
    "  ax1.set_xlabel('Epoch')\n",
    "  ax1.legend(['Train', 'Validation'])\n",
    "\n",
    "  # Plot accuracy\n",
    "  ax2.set_title('Accuracy')\n",
    "  ax2.plot(history.history['accuracy'],  label = 'train')\n",
    "  ax2.plot(history.history['val_accuracy'], label = 'test')\n",
    "  ax2.set_ylabel('Accuracy')\n",
    "  ax2.set_ylim([0, 1])\n",
    "  ax2.set_xlabel('Epoch')\n",
    "  ax2.legend(['Train', 'Validation'])\n",
    "  plt.savefig(\"loss.png\")\n",
    "  plt.show()\n",
    "\n",
    "plot_history(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NqgbzOiKuxxT",
    "outputId": "4f6bdbe5-a2e2-4339-e018-e03bd4d39981"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VIPRaXid-uv"
   },
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hssSdW9XHF_j"
   },
   "outputs": [],
   "source": [
    "def get_actual_predicted_labels(model,dataset):\n",
    "  \"\"\"\n",
    "    Create a list of actual ground truth values and the predictions from the model.\n",
    "\n",
    "    Args:\n",
    "      dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n",
    "\n",
    "    Return:\n",
    "      Ground truth and predicted values for a particular dataset.\n",
    "  \"\"\"\n",
    "  actual = [labels for _, labels in dataset.unbatch()]\n",
    "  predicted = model.predict(dataset)\n",
    "\n",
    "  actual = tf.stack(actual, axis=0)\n",
    "  predicted = tf.concat(predicted, axis=0)\n",
    "  predicted = tf.argmax(predicted, axis=1)\n",
    "\n",
    "  return actual, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GlFJ9Nd3dh-I",
    "outputId": "a3d7768e-4c3d-43c5-9444-0571e29dae63"
   },
   "outputs": [],
   "source": [
    "actual, predicted = get_actual_predicted_labels(model,test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_V8rk7HBIVI2"
   },
   "outputs": [],
   "source": [
    "labels = classes_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rX_OAcP7QwA-",
    "outputId": "6c4b113f-1688-47c4-fbe4-15b2f0750f79"
   },
   "outputs": [],
   "source": [
    "print(actual, tf.cast(predicted, tf.int16),labels, len(labels),sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGB8UOlWT_ZW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "con_mat = tf.math.confusion_matrix(labels=actual, predictions=predicted).numpy()\n",
    "# con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat,\n",
    "                     index = labels,\n",
    "                     columns = labels)\n",
    "\n",
    "figure = plt.figure(figsize=(9, 9))\n",
    "sns.heatmap(con_mat_df, annot=True, fmt='g')\n",
    "# sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig('Confusion_martix_test.png',bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "i6Q3YmE3guKS",
    "outputId": "850e7f94-5f08-4cde-f744-7dd23eebc36a"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "\n",
    "# Open the image\n",
    "image_path = '/content/video_classification/Confusion_martix_test.png'  # Replace with the actual path to your image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Define the desired output size\n",
    "output_size = (700, 700)  # Replace with your desired size\n",
    "\n",
    "# Resize the image\n",
    "image_resized = image.resize(output_size)\n",
    "\n",
    "# Display the resized image\n",
    "display.display(image_resized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6s9Q_JBcVmN1"
   },
   "source": [
    "## Inferencing using the trained model on GIF\n",
    "\n",
    "The same can be done on video input by following bellow method\n",
    "\n",
    "In case of video input with shape ```(1, N*8, 244, 244, 3)``` we can split it into multiple samples with size ```( 1, 8, 244, 244, 3)``` and do the inference in a loop to obtain realtime detection results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clvovH70zfAx"
   },
   "source": [
    "Check what the classes are and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sb-x2rSIytYk"
   },
   "outputs": [],
   "source": [
    "classes_1 = ['Archery',\n",
    " 'BabyCrawling',\n",
    " 'BoxingPunchingBag',\n",
    " 'BoxingSpeedBag',\n",
    " 'CliffDiving',\n",
    " 'CuttingInKitchen',\n",
    " 'Diving',\n",
    " 'Fencing',\n",
    " 'Hammering',\n",
    " 'HammerThrow',\n",
    " 'HighJump',\n",
    " 'HulaHoop',\n",
    " 'IceDancing',\n",
    " 'JavelinThrow',\n",
    " 'LongJump',\n",
    " 'Mixing',\n",
    " 'MoppingFloor',\n",
    " 'PoleVault',\n",
    " 'Punch',\n",
    " 'SalsaSpin',\n",
    " 'Shotput',\n",
    " 'SumoWrestling',\n",
    " 'TaiChi',\n",
    " 'ThrowDiscus',\n",
    " 'TrampolineJumping']\n",
    "\n",
    "NUM_CLASSES = len(classes_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AVipA1RzelN"
   },
   "source": [
    " The code takes a list of class labels `classes_1`, creates a list of unique classes, and generates one-hot encoded labels for each class in the original list. The resulting one-hot encoded labels are stored in the `labels_1` variable, which can be further used for tasks such as training machine learning models or performing categorical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VMeYGgKyyue"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "classes_one_hot = classes_1\n",
    "\n",
    "# Create a list of unique classes\n",
    "unique_classes = np.unique(classes_one_hot)\n",
    "\n",
    "# Create one-hot encoded labels\n",
    "labels = []\n",
    "for c in classes_1:\n",
    "    label = np.asarray([1 if c == cls else 0 for cls in unique_classes])\n",
    "    labels.append(label)\n",
    "\n",
    "labels_1 = np.asarray(labels)\n",
    "\n",
    "# print(labels_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NH0VOF6U0Eiv"
   },
   "source": [
    "The provided code is designed for video inference in order to visualize the predicted output. It includes helper `load_gif`, `get_top_k` and `predict_top_k` functions that have been defined to facilitate smooth execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUVINqlifedS"
   },
   "outputs": [],
   "source": [
    "def load_gif(file_path, image_size=(224, 224)):\n",
    "  \"\"\"Loads a gif file into a TF tensor.\"\"\"\n",
    "  with tf.io.gfile.GFile(file_path, 'rb') as f:\n",
    "    video = tf.io.decode_gif(f.read())\n",
    "  video = tf.image.resize(video, image_size)\n",
    "  video = tf.cast(video, tf.float32) / 255.\n",
    "  return video\n",
    "\n",
    "def get_top_k(probs, k=5, label_map=classes_1):\n",
    "  \"\"\"Outputs the top k model labels and probabilities on the given video.\"\"\"\n",
    "  top_predictions = tf.argsort(probs, axis=-1, direction='DESCENDING')[:k]\n",
    "  top_labels = tf.gather(label_map, top_predictions, axis=-1)\n",
    "  top_labels = [label.decode('utf8') for label in top_labels.numpy()]\n",
    "  top_probs = tf.gather(probs, top_predictions, axis=-1).numpy()\n",
    "  return tuple(zip(top_labels, top_probs))\n",
    "\n",
    "def predict_top_k(model, video, k=5, label_map=classes_1):\n",
    "  \"\"\"Outputs the top k model labels and probabilities on the given video.\"\"\"\n",
    "  outputs = model.predict(video[tf.newaxis])[0]\n",
    "  probs = tf.nn.softmax(outputs)\n",
    "  return get_top_k(probs, k=k, label_map=label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFDxWKZe2ke2"
   },
   "source": [
    "This folder is created for storing gif of the later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "b9HLOTgeUj4o"
   },
   "outputs": [],
   "source": [
    "!mkdir sample_gifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn8rE4462suK"
   },
   "source": [
    "The purpose of the code below is to traverse through all the files in the '/content/video_classification/UCF101_subset/test' directory. It randomly selects five videos from this directory for inference. Subsequently, it converts these selected videos into GIF format and saves them in the '/content/video_classification/sample_gifs' folder. The generated GIFs can be used for future inference tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ni5_vjoHRa-C",
    "outputId": "8b4c42e8-13ba-4e90-b3b6-2ff2cf544bc6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Specify the directory path\u001b[39;00m\n\u001b[0;32m      6\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/video_classification/UCF101_subset/test\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'moviepy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Specify the directory path\n",
    "directory = '/content/video_classification/UCF101_subset/test'\n",
    "save_dir = '/content/video_classification/sample_gifs'\n",
    "\n",
    "# Get a list of subdirectories within the main directory\n",
    "subdirectories = [subdir for subdir in os.listdir(directory) if os.path.isdir(os.path.join(directory, subdir))]\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    subdir = random.choice(subdirectories)\n",
    "    # Iterate over each subdirectory\n",
    "    # for subdir in subdirectories:\n",
    "    subdir_path = os.path.join(directory, subdir)\n",
    "    # Get a list of files within the subdirectory with the .avi extension\n",
    "    files = [file for file in os.listdir(subdir_path) if file.endswith('.avi')]\n",
    "\n",
    "    # Randomly select a file from the files list\n",
    "    random_file = random.choice(files)\n",
    "\n",
    "    # Print the selected file\n",
    "    print(\"Random .avi file from\", subdir, \":\", random_file)\n",
    "    input = directory+'/'+subdir+'/'+random_file\n",
    "    clip = VideoFileClip(input)\n",
    "    output = save_dir+'/'+random_file.split('.')[0]+'.gif'\n",
    "    print(output)\n",
    "    clip.write_gif(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQiAxCJ53sjT"
   },
   "source": [
    "\n",
    "The provided code iterates through all the files in the '/content/video_classification/sample_gifs' directory. It utilizes these files for video classification and presents the output in the form of a GIF and displays the top five predictions associated with the video classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "toT3DpzSSdfp",
    "outputId": "c6b2ac37-91e1-49e3-d93d-3915ea02486d"
   },
   "outputs": [],
   "source": [
    "save_dir = '/content/video_classification/sample_gifs'\n",
    "files = [file for file in os.listdir(save_dir) if file.endswith('.gif')]\n",
    "for file_name in files:\n",
    "  file_name = save_dir+'/'+file_name\n",
    "  video = load_gif(file_name, image_size=(244, 244))\n",
    "  media.show_video(video.numpy(), fps=23)\n",
    "  outputs = predict_top_k(model, video)\n",
    "  for label, prob in outputs:\n",
    "    print(label, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-0icb1deyyKO",
    "outputId": "706bee18-fa03-4ecc-c908-1ed22855cb5f"
   },
   "outputs": [],
   "source": [
    "save_dir = '/content/video_classification/sample_gifs'\n",
    "files = [file for file in os.listdir(save_dir) if file.endswith('.gif')]\n",
    "for file_name in files:\n",
    "  file_name = save_dir+'/'+file_name\n",
    "  video = load_gif(file_name, image_size=(244, 244))\n",
    "  media.show_video(video.numpy(), fps=23)\n",
    "  outputs = predict_top_k(model, video)\n",
    "  for label, prob in outputs:\n",
    "    print(label, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "dPx7Pp7fbgLY",
    "KbhwWLLM7FXo",
    "aYYShfhMx9DW",
    "1UsxiPs8yA2e",
    "YDk6LAciJfnA",
    "KkLl2zF8G9W0",
    "6s9Q_JBcVmN1"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
